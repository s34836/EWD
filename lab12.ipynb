{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s34836/EWD/blob/main/lab12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71bea0a1-71ab-433b-b538-5abaa4697877",
      "metadata": {
        "id": "71bea0a1-71ab-433b-b538-5abaa4697877"
      },
      "source": [
        "# Lab - Trees\n",
        "\n",
        "## Tasks\n",
        "\n",
        "1. Load the `Carseats.csv` dataset. Drop the `Sales` column and replace it with a categorical column `SalesHigh`, which should take the value `Yes` if `Sales >= 8` and `No` otherwise. Use decision trees to predict the value of `SalesHigh` based on the other variables.\n",
        "    - Divide the data into training, validation and test sets (or use cross validation instead of validation set).\n",
        "    - Fit a [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) model.\n",
        "    - Apply pruning to reduce the size of the tree. Generate `ccp_alpha` values with the `cost_complexity_pruning_path()` method. Find the best `ccp_alpha` using the validation set or cross validation (e.g. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
        "    - Compare the pruned and unpruned trees. How did pruning affect the quality of predictions? How did it affect the size of the model (compare tree sizes using the methods `get_depth()` and `get_n_leaves()`).\n",
        "    - Fit a [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and compare it to single-tree models.\n",
        "    - Select the best decision tree, taking into account both prediction accuracy and model size. Visualize the tree using the method [`plot_tree()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html). Use the test set to evaluate the model.\n",
        "2. Use the [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) and [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) models to predict the value of `medv` based on the other variables in the `boston.csv` dataset. Follow the steps from Task 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('Carseats.csv')\n",
        "df['SalesHigh'] = ['Yes' if x >= 8 else 'No' for x in df['Sales']]\n",
        "df = df.drop('Sales', axis=1)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_Vhho3uO7vB",
        "outputId": "46ab599f-b828-4c89-c3eb-77a8849cbb0a"
      },
      "id": "p_Vhho3uO7vB",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
            "0        138      73           11         276    120       Bad   42   \n",
            "1        111      48           16         260     83      Good   65   \n",
            "2        113      35           10         269     80    Medium   59   \n",
            "3        117     100            4         466     97    Medium   55   \n",
            "4        141      64            3         340    128       Bad   38   \n",
            "\n",
            "   Education Urban   US SalesHigh  \n",
            "0         17   Yes  Yes       Yes  \n",
            "1         10   Yes  Yes       Yes  \n",
            "2         12   Yes  Yes       Yes  \n",
            "3         14   Yes  Yes        No  \n",
            "4         13   Yes   No        No  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_val_data, test_data = train_test_split(df, test_size=0.2, random_state=1)\n",
        "train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=1)\n",
        "\n",
        "print(f\"Full dataset shape: {df.shape}\")\n",
        "print(f\"Training set shape: {train_data.shape}\")\n",
        "print(f\"Validation set shape: {val_data.shape}\")\n",
        "print(f\"Test set shape: {test_data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajl5jvyRPfxe",
        "outputId": "a3dad258-729f-42c3-a199-12416aa3c24c"
      },
      "id": "ajl5jvyRPfxe",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset shape: (400, 11)\n",
            "Training set shape: (240, 11)\n",
            "Validation set shape: (80, 11)\n",
            "Test set shape: (80, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data.drop('SalesHigh', axis=1)\n",
        "y_train = train_data['SalesHigh']\n",
        "\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Print model information\n",
        "print(\"Decision Tree model has been fitted.\")\n",
        "print(f\"Number of nodes: {dt_model.tree_.node_count}\")\n",
        "print(f\"Depth of tree: {dt_model.get_depth()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii3Rrnh4P-rm",
        "outputId": "465bc914-0053-4cbc-f609-89e3f0f5d092"
      },
      "id": "Ii3Rrnh4P-rm",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree model has been fitted.\n",
            "Number of nodes: 81\n",
            "Depth of tree: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare validation data the same way as training data\n",
        "X_val = val_data.drop('SalesHigh', axis=1)\n",
        "y_val = val_data['SalesHigh']\n",
        "X_val = pd.get_dummies(X_val, drop_first=True)\n",
        "\n",
        "# Get the cost complexity pruning path\n",
        "path = dt_model.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "# Remove the last alpha which is the largest and would give a trivial tree\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "# Create trees with different alphas and evaluate on validation set\n",
        "acc_scores = []\n",
        "trees = []\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    dt = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    dt.fit(X_train, y_train)\n",
        "    y_val_pred = dt.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    acc_scores.append(acc)\n",
        "    trees.append(dt)\n",
        "\n",
        "# Find the best alpha\n",
        "best_alpha_idx = np.argmax(acc_scores)\n",
        "best_alpha = ccp_alphas[best_alpha_idx]\n",
        "best_tree = trees[best_alpha_idx]\n",
        "\n",
        "print(f\"Best ccp_alpha: {best_alpha}\")\n",
        "print(f\"Validation accuracy with best alpha: {acc_scores[best_alpha_idx]}\")\n",
        "print(f\"Original tree nodes: {dt_model.tree_.node_count}, depth: {dt_model.get_depth()}\")\n",
        "print(f\"Pruned tree nodes: {best_tree.tree_.node_count}, depth: {best_tree.get_depth()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcIfFqbKQhIp",
        "outputId": "cfe3e1c8-9325-44b1-832c-27710567efb6"
      },
      "id": "rcIfFqbKQhIp",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ccp_alpha: 0.005263157894736845\n",
            "Validation accuracy with best alpha: 0.8\n",
            "Original tree nodes: 81, depth: 10\n",
            "Pruned tree nodes: 59, depth: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare pruned and unpruned trees\n",
        "\n",
        "# Evaluate unpruned tree on validation set\n",
        "y_val_pred_unpruned = dt_model.predict(X_val)\n",
        "unpruned_accuracy = accuracy_score(y_val, y_val_pred_unpruned)\n",
        "\n",
        "# Evaluate pruned tree on validation set\n",
        "y_val_pred_pruned = best_tree.predict(X_val)\n",
        "pruned_accuracy = accuracy_score(y_val, y_val_pred_pruned)\n",
        "\n",
        "# Evaluate both models on test set\n",
        "X_test = test_data.drop('SalesHigh', axis=1)\n",
        "y_test = test_data['SalesHigh']\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "\n",
        "# Ensure test set has same columns as training set\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "y_test_pred_unpruned = dt_model.predict(X_test)\n",
        "y_test_pred_pruned = best_tree.predict(X_test)\n",
        "\n",
        "unpruned_test_accuracy = accuracy_score(y_test, y_test_pred_unpruned)\n",
        "pruned_test_accuracy = accuracy_score(y_test, y_test_pred_pruned)\n",
        "\n",
        "# Compare model sizes\n",
        "print(\"\\nComparison of Tree Sizes:\")\n",
        "print(f\"Unpruned Tree - Depth: {dt_model.get_depth()}, Leaves: {dt_model.get_n_leaves()}, Nodes: {dt_model.tree_.node_count}\")\n",
        "print(f\"Pruned Tree - Depth: {best_tree.get_depth()}, Leaves: {best_tree.get_n_leaves()}, Nodes: {best_tree.tree_.node_count}\")\n",
        "print(f\"Reduction in Depth: {dt_model.get_depth() - best_tree.get_depth()} ({(1 - best_tree.get_depth()/dt_model.get_depth())*100:.1f}%)\")\n",
        "print(f\"Reduction in Leaves: {dt_model.get_n_leaves() - best_tree.get_n_leaves()} ({(1 - best_tree.get_n_leaves()/dt_model.get_n_leaves())*100:.1f}%)\")\n",
        "print(f\"Reduction in Nodes: {dt_model.tree_.node_count - best_tree.tree_.node_count} ({(1 - best_tree.tree_.node_count/dt_model.tree_.node_count)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nComparison of Prediction Quality:\")\n",
        "print(f\"Validation Set - Unpruned Accuracy: {unpruned_accuracy:.4f}, Pruned Accuracy: {pruned_accuracy:.4f}\")\n",
        "print(f\"Test Set - Unpruned Accuracy: {unpruned_test_accuracy:.4f}, Pruned Accuracy: {pruned_test_accuracy:.4f}\")\n",
        "\n",
        "# Calculate if pruning helped with overfitting by comparing train-test accuracy differences\n",
        "X_train_eval = X_train\n",
        "y_train_pred_unpruned = dt_model.predict(X_train_eval)\n",
        "y_train_pred_pruned = best_tree.predict(X_train_eval)\n",
        "unpruned_train_accuracy = accuracy_score(y_train, y_train_pred_unpruned)\n",
        "pruned_train_accuracy = accuracy_score(y_train, y_train_pred_pruned)\n",
        "\n",
        "unpruned_overfit = unpruned_train_accuracy - unpruned_test_accuracy\n",
        "pruned_overfit = pruned_train_accuracy - pruned_test_accuracy\n",
        "\n",
        "print(\"\\nOverfitting Analysis:\")\n",
        "print(f\"Unpruned Tree - Train Accuracy: {unpruned_train_accuracy:.4f}, Test Accuracy: {unpruned_test_accuracy:.4f}, Difference: {unpruned_overfit:.4f}\")\n",
        "print(f\"Pruned Tree - Train Accuracy: {pruned_train_accuracy:.4f}, Test Accuracy: {pruned_test_accuracy:.4f}, Difference: {pruned_overfit:.4f}\")\n",
        "if unpruned_overfit > pruned_overfit:\n",
        "    print(\"The pruned tree shows less overfitting compared to the unpruned tree.\")\n",
        "else:\n",
        "    print(\"The pruned tree does not show reduced overfitting compared to the unpruned tree.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Besxaf0XR8jx",
        "outputId": "82ad56f1-5bd5-4187-bd36-d26002090211"
      },
      "id": "Besxaf0XR8jx",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of Tree Sizes:\n",
            "Unpruned Tree - Depth: 10, Leaves: 41, Nodes: 81\n",
            "Pruned Tree - Depth: 10, Leaves: 30, Nodes: 59\n",
            "Reduction in Depth: 0 (0.0%)\n",
            "Reduction in Leaves: 11 (26.8%)\n",
            "Reduction in Nodes: 22 (27.2%)\n",
            "\n",
            "Comparison of Prediction Quality:\n",
            "Validation Set - Unpruned Accuracy: 0.7750, Pruned Accuracy: 0.8000\n",
            "Test Set - Unpruned Accuracy: 0.8000, Pruned Accuracy: 0.8125\n",
            "\n",
            "Overfitting Analysis:\n",
            "Unpruned Tree - Train Accuracy: 1.0000, Test Accuracy: 0.8000, Difference: 0.2000\n",
            "Pruned Tree - Train Accuracy: 0.9750, Test Accuracy: 0.8125, Difference: 0.1625\n",
            "The pruned tree shows less overfitting compared to the unpruned tree.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}